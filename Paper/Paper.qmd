---
title: "Tails or Types? A Critical Systematic Review of Taxometric Studies in Neurodevelopmental Disorders"
shorttitle: "Taxometric Review Neurodevelopmental Disorders"
authors:
  - name: Enrico Toffalini
    corresponding: true
    orcid: 0000-0002-1404-5133
    email: enrico.toffalini@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Margherita Calderan
    corresponding: false
    orcid: 0009-0005-5668-5162
    email: margherita.calderan@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Riccardo Pagan
    corresponding: false
    email: riccardo.pagan.3@studenti.unipd.it
    affiliation: Department of Social and Developmental Psychology, University of Padua, Italy
  - name: Valentina Tobia
    corresponding: false
    email: tobia.valentina@unisr.it
    affiliation: University Vita-Salute San Raffaele, Milan, Italy
author-note:
  disclosures:
    study-registration: 'The review was preregistered at https://osf.io/65y9g/?view_only=91e97c6b00dc444abb83fefcf67cbac0'
    financial-support: 'Financial support: Project 2022KBW99S "Tails or types? Testing the dimensional hypothesis in neurodevelopmental disorders", funded by Next Generation EU, Mission 4, Componente 1, CUP C53D23004210006'
    gratitude: "We are grateful to Athanasia Vasileiadou who first pointed us to some of the reviewed articles."
    data-sharing: https://osf.io/ys5ad/?view_only=0e2812acfabf43fc8af01f883c7331ba
    related-report: null
    conflict-of-interest: null
    authorship-agreements: null
abstract: "..."
keywords: [Neurodevelopmental disorders, Taxometric analysis, Autism, ADHD, Learning disorders]
bibliography: references.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-typst: default
  apaquarto-pdf:
    documentmode: man
---

```{r,message=F,warning=F}
library(readxl)
library(kableExtra)
library(stringr)
library(dplyr)
```

In recent years, research on neurodevelopmental disorders (NDDs) has undergone widespread reconsiderations. Traditional diagnostic categories defined in the DSM-5 [@dsm5], have been increasingly called into question in favor of a dimensional and transdiagnostic view [e.g., @astle2022trandiagnostic; @michelini2024world; @happe2020looking; @happe2021both; @sonuga2020kuhnian; @caviola2024editorial]. The DSM-5 itself has incorporated dimensional aspects, for example in defining a broad Autistic Spectrum Disorder (ASD) condition instead of a set of different autism-related diagnoses. Several arguments have contributed to this: the large heterogeneity within diagnostic groups, the poor alignment between data-driven clusters and DSM-based categories, the frequent comorbidity and phenotypic correlations across conditions, and the idea that individuals with NDDs might represent, at least in part, the tails of developmental continua, that are quantitatively rather than qualitatively different from the so-called neurotypical population [@michelini2024world; @happe2021both; @mammarella2021nocore].

Clarifying whether NDDs truly represent categories, rather than just tails of continuous distributions that span across the population, is important for different reasons. These involve quests about social and personal self-identity by involved individuals, discussions about diagnostic framing, comorbidity, and the choice on interventions in clinical settings, the structuring of classes, schools, and educational methods when dealing with neurodiversity, and applications to research design, planning of studies, and power analysis in research settings [@caviola2024editorial]. But most importantly, this is relevant for our understanding of the ontological status of reality, which should matter for scientific endeavor.

A dimensional approach fits well with long-standing principles in the study of individual differences in psychology, and has long characterized research on intelligence and personality [@caviola2024editorial]. It also seems appropriate for NDDs given accumulating evidence of polygenicity and multifactorial etiology [@plomin2005generalist; @kovas2006generalist; @pennington2012multiple; @astle2020core; @caviola2024editorial; @demontis2023adhdgenome]. In fact, most behavioral traits are believed to be influenced not by one or a few, but by many small, additive causes [@chabris2015fourth]. According to a famous principle known in statistics as the central limit theorem [@fischer2011central], when many individual causes (even discrete ones, e.g., gene variants) add up they converge to a joint distribution that tends to continuity and normality: this is, in fact, the "secret" of the Gaussian distribution. Nonetheless, a principled categorical view still resists in neurodevelopmental research, for example concerning ASD [e.g., @happe2021both; @chown2021bit; @frazier2023asd], subtypes within NDDs [e.g., @burgess2018taxodyslexia] or the possible emergence of new data-driven taxa [@astle2022trandiagnostic].

Adjudicating between whether a clinical diagnostic category is characterized by an underlying structure that is categorical or dimensional is precisely the focus of taxometric analysis, a set of quantitative methods that have been developed since the 1990s [e.g., @meehl1995taxometric]. Since then, taxometric analysis has been widely applied in psychopathology, generally providing evidence that most mental health conditions (e.g., depression, anxiety) are best conceptualized as dimensional rather than categorical [@haslam2012review; @haslam2020metaanalysis]. In brief, taxometric methods such as MAMBAC, MAXCOV, MAXEIG, and L-Mode, leverage patterns of covariation among observed indicators to test alternative competing latent models that are categorical or dimensional [@ruscio2007taxometric; @ruscio2004checklist; @cole2004taxometric]. Such methods have become increasingly refined through simulation-based techniques such as the Comparison Curve Fit Index (CCFI), which provide criteria for objective decision-making [@ruscio2018using].

Despite this, the use of taxometric analysis in neurodevelopmental research has been limited. Most existing studies focus on adult psychopathology, with few exceptions [@beauchaine2003taxometrics; @haslam2020metaanalysis]. @happe2021both and @chown2021bit in their debate on whether ASD is a category or a continuum not even mention the potential of taxometric analysis. In their recent influential article, @astle2022trandiagnostic briefly presents taxometry but gives it little emphasis, prevailing reviewing studies that employ cluster analysis. However, the limitations of clustering for taxometric purposes have been discussed for decades. Clustering algorithms tend to impose (rather than seek) categorical structure, often fail to recover known taxa in simulations, and generally provide weak tests of taxonicity [@beauchaine2003taxometrics]. Recent studies simulating realistic psychological data, characterized by a combination of (even modestly) skewed and correlated indicators, further suggest that common clustering algorithms easily detect pseudoclusters while having low power to test the existence of true taxa [@toffalini2022entia; @toffalini2024clusters]. Indeed, @astle2022trandiagnostic interpret results from clustering studies as evidence that data-driven structures fail to align with the expected DSM-5 categories, rather than as proper tests of taxonicity.

Taxometric analysis is not without limitations, however, some of which are shared with cluster analysis. Commonly cited threats to validity of taxometric conclusions include poor indicator validity, nuisance covariance, low base rate, and artificial admixture \[...\]. Poor indicator validity occurs when taxometric analysis is run on variables that present little mean differences between individuals with and without the target disorder (i.e., putatively, the taxon and the complement). Generally, it is recommended that Cohen's d ≫ 1 on each indicator. Nuisance covariance means that there is strong residual correlations after accounting for taxa (i.e., both within the taxon and the complement), thus reflecting the use of redundant indicators; residual r \> 0.40 is often regarded as problematic. Low base rate means that individuals with the taxonic condition are too few in the sample for taxometric analysis to correctly identify them; n \< 30 is often regarded as problematic. This is obviously a problem when the diagnostic category is rare (e.g., 1-2% of the population). Finally, artificial admixture consists of mixing participants selected or recruited using alternate criteria. This is often (incorrectly) used to compensate for the low base rate, with many individuals with a diagnosis being recruited separately from the rest of the sample to increase the number of observations with the putative taxon. Poor indicator validity and low base rate risk masking detection of taxa, while strong nuisance covariance and artificial admixture risk to detecting pseudotaxa by mimicking categorical structures.

## Goals of the Present Review

The main goal of this systematic review is to critically examine the use of taxometric methods in the study of neurodevelopmental disorders (NDDs) within the published literature. We focused our review on the most commonly studied NDD categories: Autism Spectrum Disorder (ASD), Attention-Deficit/Hyperactivity Disorder (ADHD), and all forms of Specific Learning Disorders (SLDs), along with the closely related condition of Language Disorder/Impairment (the latter was not included in the preregistered protocol and thus constitutes a deviation). We excluded Intellectual Disability, as its etiological basis is often well identified and taxonic by definition in many cases (e.g., Down syndrome), or associated with identifiable medical risk factors. Residual non-syndromic cases, in turn, are thought to reflect the lower tail of general mental ability, and thus as inherently dimensional.

A core aim of the review is to critically assess the methodological quality and credibility of findings reported in published taxometric studies. We evaluated potential sources of bias such as artificial admixture, and whether sufficiently complete methodological information was reported to judge other threats to validity, including low indicator validity, nuisance covariance, and the skewness of indicators. (The latter is relevant when scales assess rare or extreme behaviors, and can create the illusion of categorical structure).

Following this systematic review, we present a Monte Carlo simulation study to empirically demonstrate the extent to which artificial admixture can lead to false detection of categorical latent structures in dimensional data, both when using taxometric analysis and cluster analysis.

# Systematic Review of Taxometric Analysis on NDDs

## Methods

The systematic review was conducted according to the Preferred Reporting items for Systematic Reviews and Meta-Analysis 2020 guidelines. A review protocol was preregistered on OSF registries at the following link: https://osf.io/65y9g/?view_only=91e97c6b00dc444abb83fefcf67cbac0 The methods are detailed below.

### Sources and Search strategy

A systematic search was conducted for relevant peer-reviewed articles in April 2025 using four electronic databases: PsycINFO, PubMed, Scopus, Web of Science. No time limits were set, although no records were expected from before 1990, as taxometric methods were not yet developed or diffuse then. The following search query, reflecting the methods and the target populations of interest, was performed on titles, abstracts, and keywords:

((“taxometric\*” OR “MAMBAC” OR “MAXCOV” OR “MAXEIG” OR “L-Mode”) AND (“autis\*” OR “ASD” OR “attention-deficit\*” OR “ADHD” OR “learning dis\*” OR “reading dis\*” OR “dyslexia” OR “math\* dis\*" OR "math\* diff\*"))

in databases where the wildcard "\*" was not supported (i.e., PubMed), it was replaced with full terms ("disorder", "disability" instead of "dis\*"; "mathematical", "mathematics", "math" instead of "math\*").

Language disorder was subsequently added as a deviation from preregistration, replacing the second part of the above search query with ("language imp\*" OR "language dis\*"). In addition, the full search query was launched on Google Scholar and the first 10 pages were screened; the references of and citations to @haslam2020metaanalysis were searched on Google Scholar for additional results; and a deep research via OpenAI's gpt-4o was launched providing it the preregistration protocol as context. All promising records thus emerging and not previously identified via databases, were listed under the *"Identification of studies via other methods"* section of the PRISMA flowchart.

### Eligibility Criteria

Inclusion criteria were: 1) the study applies at least one taxometric procedure (e.g., MAMBAC, MAXCOV, L-Mode, MAXEIG); 2) the target population is individuals with NDDs or related traits; 3) the study draws a conclusion about the latent structure (categorical vs. dimensional) or reports sufficient information for an independent reader to reach a conclusion based on those results (e.g., reports CCFIs).

Exclusion criteria were: 1) the study only reports a theoretical, methodological, or simulation articles without empirical data; 2) the article does not report any behavioral data (e.g., only neuroimaging or neurophysiological data; this was later reconsidered, but no studies were excluded for this reason in any case); 3) the study only consists of a review and/or meta-analysis; 4) the study employs other latent structure methods only (e.g., LPA, mixture modeling), and not taxometric analysis. In addition, following the preregistration protocol, the search was limited to published, peer-reviewed journal articles, as a primary aim was to provide a critical review of the existing literature. However, one potentially interesting record excluded as non-journal article was separately discussed below in the Results section.

### Screening and Coding

Two independent human coders (MC and RP) screened and coded all articles. No AI tools were used in the process, except in occasional cases by the human coders to assist them clarify the content of articles. All discrepancies were resolved through discussion, and later revised by the PI (ET).

Since a single article could report multiple (sub)samples and/or multiple taxometric analyses on the same sample, the full coded dataframe followed a long-form data structure, with some articles repeating over multiple rows. Coded variables were listed in the data dictionary table defined in the preregistration protocol, to which a few variables for notes and coders agreement were added.

Inter-coder agreement was fair to good in all phases. For the title+abstract screening phase, Cohen's k = 0.79 (34 out of 38 matching independent decisions); for the full-text eligibility screening, Cohen's k = 0.52 (15 out of 19). For final data extraction, 84% (71 out of 85) rows were extracted by both coders, with good agreement on the crucial information: for the "authors' taxonic conclusion" agreement was 94%, for artificial admixture was 95% at the sample/subsample level.

## Results

A total of 110 records were identified through database searches. After removing 67 duplicates and excluding 5 records (dissertations or book sections, only one of which appeared to include primary taxometric analyses, but could not be retrieved), 38 unique articles were screened. Nineteen were excluded at the title/abstract level. Full-text assessment was conducted on the remaining 19 reports, with 7 excluded for not meeting inclusion criteria (4 did not use taxometric analysis; 3 did not target neurodevelopmental disorders). An additional 4 records were identified through citation tracking and online browsing, of which 2 were excluded (1 methodological article; 1 not employing taxometric methods). In total, 14 studies were included in the review. The PRISMA flowchart in @fig-prisma summarizes the selection process.

@fig-prisma *about here*

![PRISMA 2020 flow diagram illustrating the study screening and selection process](Figures/PRISMA_flow_diagram.png){#fig-prisma}

```{r}
df = data.frame(read_excel("../Literature-review/data/data_extraction.xlsx"))
```

An overview summary of the results (simplified to one row per article) is reported in @tbl-summary. A fully detailed reporting of coded data for all taxometric analyses is available in Supplemental online material. The total number of taxometric analyses was `r nrow(df)`, spanning from `r min(table(df$ID_article))` to `r max(table(df$ID_article))` per article. Targeted disorders were ADHD (6 articles), ASD (6 articles), Dyslexia (1 article), and Specific Language Impairment (SLI; 2 articles), with one article targeting both ADHD and ASD. Most articles (10 out of 14) focused on whether disorders were taxa, while the remaining 4 articles targeted whether subtypes were taxa.

The most used taxometric method was MAMBAC, used in 13 out of 14 articles and in `r sum(grepl("MAMBAC",df$Taxometric_methods_used))` out of `r nrow(df)` total analyses, followed by MAXEIG (9 articles), L-Mode (7 articles), MAXCOV (2 articles), and MAXSLOPE (1 article). In most articles more than one taxometric method was used, with a median of `r median(str_count(df$Taxometric_methods_used,";")+1)` methods per analysis. In 11 out of 14 articles the interpretation was based on a quantitative index (Fit~d~ or, for more recent articles, CCFI), while in the remaining 3 cases the interpretation was based on visual inspection of taxometric curves. The number of indicators entered in the analyses spanned from `r min(df$Indicators_number,na.rm=T)` to `r max(df$Indicators_number,na.rm=T)`, with a median of `r median(df$Indicators_number,na.rm=T)` (excluding one article where the number was unclear). The median sample size across all analyses was `r median(df$Sample_size)`, or `r median((df |> group_by(ID_article) |> summarize(avg = mean(Sample_size)))$avg)` after averaging within article.

Taxonic conclusions were mixed. All 5 articles targeting ADHD as a disorder concluded in favor of a dimensional structure, as did both articles targeting SLI. On the contrary, all 4 articles targeting ASD as a disorder leaned towards or clearly supported a categorical (taxonic) structure. The remaining 4 articles targeted subtypes of disorders, and all leaned towards taxonic conclusions, either strongly or predominantly [@stevens2018functional on ADHD subtypes; @munson2008asd on ASD subtypes; @obrien2012dyslexia on Dyslexia subtypes], or at least partly [@ingram2008defining, that supported ASD subtypes as taxa depending on what sets of indicators were used]. In total, 8 out of 14 articles reached taxonic conclusions on at least some of their taxometric analyses (specifically, `r sum(df$Taxonic_conclusion)` out of `r nrow(df)` total analyses, or `r round(mean(df$Taxonic_conclusion)*100,1)`%, reached a taxonic conclusion), mostly concerning ASD (`r sum(grepl("ASD",df$Target_disorder)&df$Taxonic_conclusion==1)` out of `r sum(grepl("ASD",df$Target_disorder))` analyses, or `r round(100*sum(grepl("ASD",df$Target_disorder)&df$Taxonic_conclusion==1)/sum(grepl("ASD",df$Target_disorder)),1)`%).

Artificial admixture was evident or strongly suspected, for at least part of the analyses, in 8 out of 14 articles (in total, involving `r sum(df$Artificial_admixture)` out of `r nrow(df)` analyses). Articles where artificial admixture was incurred tended to match those that reached taxonic conclusions, with 6 out of 8 cases. This matching was even higher at the level of individual analysis: taxonic conclusion was reached in `r sum(df$Taxonic_conclusion[df$Artificial_admixture==1])`out of `r sum(df$Artificial_admixture==1)` (`r round(100*mean(df$Taxonic_conclusion[df$Artificial_admixture==1]),1)`%) analyses where admixture was evident or suspected, in contrast to `r sum(df$Taxonic_conclusion[df$Artificial_admixture==0])` out of `r sum(df$Artificial_admixture==0)` (`r round(100*mean(df$Taxonic_conclusion[df$Artificial_admixture==0]),1)`%) analyses where it was probably or certainly excluded.

Remaining methodological issues concerned missing information about descriptive statistics or other indices. In particular, nuisance covariances (i.e., correlations across indicators within diagnostic group or taxa) could be coded for only 2 out of 14 articles. Where reported, it was small to negligible in @james2016latent, while above 0.40 for many indicators in @frazier2023asd; both articles reached a taxonic conclusion. Skewness of distributions of indicators scores was reported by only 5 articles, and where reported it was often close to or beyond $\pm 1$ (at least one indicator in about one third of the analyses); this was not specifically associated to reaching a taxonic conclusion. On the contrary, indicators validity was largely reported, being coded for all but 3 articles, and it was almost always large or very large ($\gg1$).

@tbl-summary *about here*

```{r}
#| label: tbl-summary
#| tbl-cap: Overview summary of the reviewed articles."
summary_tab = read_excel("Tables/Review-Summary.xlsx",sheet=2)
kable(summary_tab, format = "latex", booktabs = TRUE) |>
  kable_styling(font_size = 8, latex_options = c("striped", "scale_down")) |>
  column_spec(1:ncol(summary_tab),width="5em") |>
  landscape()
```

## Additional Use of Cluster Analysis

Among the 14 identified articles, 6 also employed methods of cluster analysis (in all but one case using latent class or latent profile analysis). In 5 of the 6 cases, cluster analysis was conducted in parallel with taxometric analysis [@james2016latent; @munson2008asd; @frazier2023asd; @frazier2007adhd; @deserno2023probing], while in one case it was performed as a secondary analysis [@frazier2010asd]. All 6 targeted ADHD and/or ASD, and in all cases clustering results were interpreted as supporting taxonic conclusions, always converging with those from taxometric analyses, with the exception of @frazier2007adhd, where clustering results were partially inconclusive yet suggested the presence of subgroups within ADHD, in contrast to the dimensional structure favored by taxometric analysis. In all but 2 studies [@frazier2007adhd; @munson2008asd], we identified at least some risk of artificial admixture.

# Simulation of Artificial Admixture

We focus on artificial admixture because it is a very powerful threat to validity that could relatively easily be avoided by design when planning a study, and because as suggested by the result of the systematic review presented below, it is unfortunately frequent. There are different types of admixtures; @ruscio2004checklist discusses three cases. First, as mentioned above, the situation where clinical and nonclinical cases are separately recruited and merged. Second, the case of splitting a sample into subsamples (using alternative criteria) and then using those to test different taxometric questions. Third, trimming away observations of the putative complement (i.e., individuals without the disorder) to increase the base rate. All of these procedures artificially impose categorical structures to the data that do not exist in the population. It is worth mentioning that artificial admixture is also a threat for any type of cluster analysis, for the exact same reasons that it is a problem for taxometric analysis.

```{r}
load("../R/simulateAdmixtResults.RData")
```

We simulate a dimensional scenario that makes it visually compelling how artificial admixture of the first type mentioned above creates pseudotaxa. A single normally-distributed latent variable $X$ is generated, that defines the target condition. A series of observed indicators $x1, x2, etc.$ are simulated, incorporating the $X$ latent variable plus some random normally-distributed noise ($R^2 = 0.77$). Individuals above the 99^th^ percentile of $X$ receive a diagnosis via clinical assessment. A sample of $N = 1000$ individuals is collected from the general population. Since the base rate is low (on average, only about $n = 10$ cases are expected to naturally present a diagnosis), researchers select and recruit an additional $n = 1000$ cases with a clinical diagnosis from the general population, thus creating artificial admixture. All data simulation is available in the online materials at https://osf.io/ys5ad/?view_only=0e2812acfabf43fc8af01f883c7331ba

An instance of the simulation, plotting two observed variables for illustrative purposes, is shown in @fig-admixture. Color is added for further clarity to distinguish individuals with and without a diagnosis, but two clusters still clearly emerge. Indicator validity is good (about $Cohen's$ $d = 2$), while nuisance covariance is partly problematic: for the clinical cases $r \approx 0$, but for the nonclinical cases $r = 0.61$. It is worth reminding that no taxa exist here, and the appearance of a categorical structure is mainly imposed by admixture, as shown below.

@fig-admixture *about here*

![A simulated example of artificial admixture, where a large number of individuals with a diagnosis are separately recruited and added to the sample (total N = 2000). The true underlying structure is strictly dimensional.](Figures/figureAdmixture.png){#fig-admixture}

A Monte Carlo simulation was then performed, with 1000 iterations. Taxometric analysis was conducted using the "RTaxometric" package of R. As recommended, CCFI was used for inference: CCFI varies between 0 (maximal evidence for dimensional structure) to 1 (maximal evidence for categorical structure), with 0.5 indicating inconclusive results. Performed procedures were, as per default: MAMBAC, MAXEIG, and L-Mode. A third $x3$ observed indicator (similar to those above) was entered to allow conducting all these taxometric procedures. Over 1000 simulated datasets, results always strongly favored a categorical structure: median combined CCFI = `r formatC(median(resultsAdmix$CCFI.mean),2,format="f")`, 95% quantile interval \[`r formatC(quantile(resultsAdmix$CCFI.mean,.025),2,format="f")`, `r formatC(quantile(resultsAdmix$CCFI.mean,.975),2,format="f")`\]; median MAMBAC CCFI = `r formatC(median(resultsAdmix$CCFI.MAMBAC),2,format="f")`; average MAXEIG CCFI= `r formatC(median(resultsAdmix$CCFI.MAXEIG),2,format="f")`; average L-Mode CCFI = `r formatC(median(resultsAdmix$CCFI.LMode),2,format="f")`. The smallest combined CCFI over 1000 iterations was `r formatC(min(resultsAdmix$CCFI.mean),2,format="f")`. Therefore, admixture can be an extremely strong driver of false categorical findings, especially when many clinical cases are separately recruited and added to the sample.

To confirm that artificial admixture leads to misleading results also when performing clustering, Gaussian Mixture Models (GMM) was also run testing 1 vs 2 components, using the "mclust" package of R. GMM is a type of finite mixture model, similar to latent profile analysis, but more flexible in that it also models indicator covariances. Over 1000 iterations, results always favored the 2-component relative to the 1-component model, with a median $\Delta BIC$ = `r formatC(median(resultsAdmix$gmmBIC1-resultsAdmix$gmmBIC2),2,format="f")` in favor of the 2-component model.

To confirm that the categorical structure was incorrectly favored specifically because of artificial admixture, we run another Monte Carlo simulation like the one above, but without admixture. In this case, a single sample of $N = 2000$ observations was drawn at each iteration. Therefore, nuisance covariance remains strong, but there is no admixture. Median combined CCFI = `r formatC(median(resultsNoAdmix$CCFI.mean),2,format="f")`, 95% quantile interval \[`r formatC(quantile(resultsNoAdmix$CCFI.mean,.025),2,format="f")`, `r formatC(quantile(resultsNoAdmix$CCFI.mean,.975),2,format="f")`\]; median MAMBAC CCFI = `r formatC(median(resultsNoAdmix$CCFI.MAMBAC),2,format="f")`; average MAXEIG CCFI= `r formatC(median(resultsNoAdmix$CCFI.MAXEIG),2,format="f")`; average L-Mode CCFI = `r formatC(median(resultsNoAdmix$CCFI.LMode),2,format="f")`. Thus, results remain frequently around inconclusive, probably due to nuisance covariance, but do not risk strongly favoring a categorical structure. GMM also consistently favored the 1-component model (over the 2-component model), with an average $\Delta BIC$ = `r formatC(median(resultsNoAdmix$gmmBIC2-resultsNoAdmix$gmmBIC1),2,format="f")` in favor of the 1-component model.

# Discussion

The first finding of our critical review was that taxometric analysis has generally been underused in neurodevelopmental research, with only 14 articles being identified. This is unfortunate in light of the unique relevance of taxometric analysis for the current debate on the categorical vs dimensional nature of NDDs [@astle2022trandiagnostic; @michelini2024world; @happe2021both; @sonuga2020kuhnian]. The underuse of taxometric analysis in this field was expected: in a meta-analysis conducted by @haslam2020metaanalysis, out 183 articles employing taxometric methods on psychopathology, only 15 were placed in the "childhood" category (this encompassed all types, even conditions such as sleep problems). Considering the studies covered in our review, only ASD, ADHD, and (to a minor extent) SLI were targeted as disorders in taxometric analysis. None of learning disorders was targeted as a taxon, with only Dyslexia being covered in one article, but only for investigating its subtypes.

Despite some heterogeneity of methods, taxometric results were seemingly quite neat: dimensional conclusions were predominantly reached for ADHD and SLI, while categorical/taxonic conclusions were predominantly reached for ASD and wherever subtypes of any disorder were considered. This parallels a conclusion already advanced by @haslam2020metaanalysis, and seems to provide a strong answer to the debate by @chown2021bit and @happe2021both . However, a closer look at the methodological limitations of the reviewed studies warrants more caution in the conclusions.

We identified four studies that targeted ASD as a disorder in taxometric analyses, and all of them reached taxonic conclusions. However, artificial admixture was identified in all of them. Artificial admixture consists of recruiting participants following alternate recruitment channels or criteria, and it is a major threat to conclusion validity, as shown in the above data simulation and in the literature \[...\]. Admixture ranged from sampling participants through different methods, only some of which explicitly targeted disorders [@james2016latent], to admixing clinical and non-clinical samples [@frazier2023asd and @deserno2023probing; in the latter case inclusion criteria from a larger database are partly unclear, but the sample is explicitly structured by diagnosis] and composing a sample including affected and unaffected siblings [@frazier2010asd]. According to our interpretation, the only unbiased taxometric evidence that ASD might be a taxon as a disorder might come from a secondary analysis by @frazier2010asd, where only unaffected siblings were examined, and a taxonic conclusion was still reached (due to the recruitment process, cases with a high level of the trait are oversampled here, but there is no explicit admixture).

Concerning subtypes the situation was similar. All four reviewed articles partly or predominantly reached taxonic conclusions, but three of them probably or mostly incurred admixture. The issue was probably less serious here. In @obrien2012dyslexia, targeting Dyslexia subtypes, we identified only partly risk of admixture, as the authors used psychometric cutoffs on alternative tools and criteria for inclusion. This might not necessarily have affected the results, unless different criteria for inclusion correlate with different underlying deficits (phonological vs non-phonological impairments), however the authors themselves comment in their discussion that: "depending on the dyslexia criterion used, samples may vary in composition with regard to their subtypes" [@obrien2012dyslexia, p.33]

Overall, at the article/sample level there were only 2 major mismatches: @marcus2012latent reached a dimensional conclusions despite incurring admixture by separately recruiting a large number of clinical cases; and @munson2008asd, who reached a taxonic conclusion about ASD subtypes despite no evidence of admixture (all children had received a diagnosis of ASD based on a seemingly uniform clinical assessment).

In the simulated example, artificial admixture was also accompanied by large nuisance covariance, although it was demonstrated that the latter posed a less severe problem to inference. In fact, the coexistence of low nuisance covariance and good indicator validity is practically impossible under a dimensional scenario. This is because an indicator can largely separate individuals with vs without a diagnosis if it is strongly related to the latent dimension, but this leads to nuisance covariance across valid indicators. Ultimately, however, such impasse might be interpreted as a direct signal that the true latent structure is dimensional.

While the DSM-5 may appear to promote a categorical model of disorders, it does not explicitly commit to a taxonic view. It is often researchers, not diagnostic manuals, who reify clinical categories as natural kinds, despite their originally pragmatic intent.

The fact that observed scores in psychology often deviate from normality [@micceri1989unicorn] may reflect psychometric characteristics (e.g., skewed indicators when observing times, accuracies, bounded sum scores) rather than the true shape of the underlying latent traits.

# References

::: {#refs}
:::
