---
title: "Tails or Types? A Critical Systematic Review of Taxometric Studies in Neurodevelopmental Disorders"
shorttitle: "Taxometric Review Neurodevelopmental Disorders"
authors:
  - name: Enrico Toffalini
    corresponding: true
    orcid: 0000-0002-1404-5133
    email: enrico.toffalini@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Margherita Calderan
    corresponding: false
    orcid: 0009-0005-5668-5162
    email: margherita.calderan@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Riccardo Pagan
    corresponding: false
    email: riccardo.pagan.3@studenti.unipd.it
    affiliation: Department of Social and Developmental Psychology, University of Padua, Italy
  - name: Valentina Tobia
    corresponding: false
    email: tobia.valentina@unisr.it
    affiliation: University Vita-Salute San Raffaele, Milan, Italy
  - name: Edmund Sonuga-Barke
    corresponding: false
    email: edmund.sonuga-barke@kcl.ac.uk
    affiliation: King’s College London, UK
author-note:
  disclosures:
    study-registration: 'Review preregistered protocol: https://osf.io/65y9g/?view_only=91e97c6b00dc444abb83fefcf67cbac0'
    financial-support: 'Financial support: Project 2022KBW99S "Tails or types? Testing the dimensional hypothesis in neurodevelopmental disorders", funded by Next Generation EU, Mission 4, Componente 1, CUP C53D23004210006'
    gratitude: "We are grateful to Athanasia Vasileiadou who first pointed us to the topic, and to some of the reviewed articles."
    data-sharing: https://osf.io/ys5ad/?view_only=0e2812acfabf43fc8af01f883c7331ba
    related-report: null
    conflict-of-interest: null
    authorship-agreements: null
abstract: "**Background.** Taxometric analysis is specifically designed to test whether the latent structures underlying clinical conditions are categorical (taxonic) or dimensional in nature. Despite its relevance to ongoing debates about the nature of neurodevelopmental conditions, its application to this field has been limited. **Methods.** We conducted a preregistered systematic review of published taxometric studies on autism, ADHD, learning disorders, and language impairment, with a focus on methodological threats such as artificial admixture (i.e., the practice of combining subsamples recruited via alternative methods, such as clinical and control groups, into a single dataset). A Monte Carlo simulation was run to illustrate how admixture can yield false taxonic results from dimensional data. **Results.** Fourteen articles met the inclusion criteria. Studies of ADHD and language impairment largely supported dimensional models, whereas most studies of autism and conditions’ subtypes supported categorical models. However, admixture was common in studies reaching taxonic conclusions, especially for autism. In simulations, admixture was consistently associated with taxonic findings despite the true structure being dimensional. **Conclusions.** Evidence for categorical structure, especially in autism and disorders’ subtypes, is likely undermined by methodological limitations, particularly admixture. We advocate for more high-quality taxometric studies in this area."
keywords: [Neurodevelopmental disorders, Taxometric analysis, Autism, ADHD, Learning disorders]
bibliography: references.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-typst: default
  apaquarto-pdf:
    documentmode: man
---

```{r,message=F,warning=F}
library(readxl)
library(kableExtra)
library(stringr)
library(dplyr)
```

In recent years, there has been a reconsideration of the conceptual foundations of neurodevelopmental conditions (NDCs). The notion that diagnostic entities defined in the DSM-5 reflect discrete categories with identifiable non-arbitrary ‘natural’ boundaries,   separating disorder from non-disorder, and one disorder from another [@dsm5] has increasingly been questioned in favor of dimensional and transdiagnostic perspectives [e.g., @astle2022trandiagnostic; @caviola2024editorial; @happe2020looking; @happe2021both; @mammarella2021nocore; @michelini2024world; @posner2020adhd; @sonuga2020kuhnian]. In fact, the issue has been discussed for a long time. @sonuga-barke1998categoricalmodels questioned whether a medical model that frames childhood conditions as categorical disorders intrinsically linked to dysfunction was appropriate and useful. While diagnostic manuals such as the DSM are presented as atheoretical, they in practice adopt a "neo-Kraepelinian" vision of psychopathology, treating disorders as natural disease entities [see also @coghill2012categories].

A dimensional perspective reinterprets NDCs as extreme variations along continuous multivariate traits that are at least quasi-normally distributed in the general population. Accordingly, individuals with NDCs are not categorically distinct, and differ quantitatively rather than qualitatively from the neurotypical population. From this perspective diagnostic thresholds are essentially arbitrary, determined not by natural discontinuities but by pragmatic considerations such as clinical need [@arildskov2022howmuch; @haslam2006latentstructure].

Determining whether NDCs represent tails of continuous distributions or discrete categories with boundaries grounded in biology or clinical reality, is important for our understanding of the ontological status of neurodevelopmental phenomena and for assessing the adequacy of the medical dysfunction paradigm. If NDCs are dimensional in nature, then the diagnostic thresholds used to categorize disorders are, by definition, arbitrary, reframing diagnostic categories as socially constructed groupings that include individuals at the margins of trait continua. The implications potentially affect how diagnosed individuals understand their social identity, how clinicians make decisions, how classrooms and support systems are organized to accommodate neurodivergence, and how research is designed and interpreted [@caviola2024editorial].

Support for a dimensional account of NDCs arises from several converging lines of evidence. First, individuals sharing the same diagnostic label often show substantial heterogeneity in symptom profiles, cognitive functioning, and developmental trajectories [e.g., @astle2022trandiagnostic]. Second, the boundaries between diagnostic categories are frequently blurred, with high comorbidity [@coghill2012categories; @michelini2024world]. Third, dimensional models are consistent with the growing evidence supporting multifactorial and polygenic etiology in NDCs [@astle2020core; @caviola2024editorial; @kovas2006generalist; @pennington2012multiple; @plomin2005generalist]. According to the central limit theorem [@fischer2011central], when many individual causes (e.g., genetic variants) contribute additively, the resulting trait tends to approximate a continuous, Gaussian distribution. Despite this body of evidence, categorical thinking still dominates parts of the neurodevelopmental literature, for example concerning the categorical nature of ASD [e.g., @chown2021bit; @frazier2023asd; @happe2021both], subtypes within NDCs [e.g., @burgess2018taxodyslexia] or the proposed interpretation of emerging data-driven taxa [@astle2022trandiagnostic].

While much of the evidence for dimensionality is circumstantial, taxometric analyses, originally introduced by Paul Meehl and colleagues [@meehl1995taxometric], were developed to provide a direct empirical test of whether latent clinical construct are categorical (taxonic) or dimensional in nature. Taxometric methods evaluate the structure of covariance among observed variables to determine whether there exists a latent boundary that divides individuals into qualitatively distinct groups. Conceptually, if such a boundary exists, it should alter and disrupt the patterns of relationships between indicators. Otherwise, the patterns are smooth and continuous across the entire range of observed values, supporting a dimensional model. Frequently used taxometric procedures include MAMBAC (Mean Above Minus Below A Cut), MAXCOV (Maximum Covariance), MAXEIG (Maximum Eigenvalue), and L-Mode (Latent Mode Factor Analysis) [@cole2004taxometric; @ruscio2007taxometric; @ruscio2004boundaryissues]. Recently, simulation-based tools such as the Comparison Curve Fit Index (CCFI) have been introduced to provide objective, quantitative indices of fit between observed data and simulated taxonic versus dimensional comparison curves, facilitating inference [@ruscio2018using].

Taxometric analyses have been widely applied in adult psychopathology, generally supporting dimensional structures for most adult psychiatric conditions [@haslam2012review; @haslam2020metaanalysis]. However, their use in neurodevelopmental research has remained limited, though the importance of taxometric methods as explicit tests for determining whether childhood disorders are categorical or dimensional has been repeatedly emphasized [@sonuga-barke1998categoricalmodels; @beauchaine2003taxometrics; @coghill2012categories]. In their debate on whether ASD reflects a category or a continuum, @happe2021both and @chown2021bit do not mention such methods. In their review, @astle2022trandiagnostic briefly acknowledge taxometry, but predominantly emphasize studies using cluster analysis (a family of data-driven methods aimed at grouping individuals based on similarity across multiple variables). However, the limitations of clustering methods for assessing taxonicity have been discussed for decades: clustering algorithms tend to impose (rather than test for) categorical structures, they provide weak tests of taxonicity, and often fail to recover known taxa in simulations [@beauchaine2003taxometrics; @ruscio2004boundaryissues]. Recent simulations using psychometrically realistic data suggest that commonly used clustering methods are prone to inflate the number of detected clusters [@toffalini2022entia; @toffalini2024clusters]. Indeed, @astle2022trandiagnostic interpreted clustering results as evidence that data-driven groups fail to align with DSM-5 categories, rather than as strong tests of taxonicity.

Like any method, taxometric analysis has its limitations. Commonly cited sources of bias in taxometric conclusions include poor indicator validity, nuisance covariance, low base rate, and artificial admixture [@cole2004taxometric; @haslam2020metaanalysis; @ruscio2018using; @ruscio2004boundaryissues; @ruscio2004checklist]. Poor indicator validity implies that indicators present little mean difference between individuals with and without the target condition. Ideally, Cohen’s *d* for each indicator should substantially exceed 1. Nuisance covariance refers to strong residual correlations among indicators after accounting for group membership, indicating redundant information. Low base rate means that too few individuals in the sample belong to the taxon, limiting power to detect it (*n \>* 30 for the taxonic group is usually considered necessary), which is problematic when studying rare conditions. Artificial admixture occurs when participants are combined from different recruitment sources or selection criteria, often as an attempt to compensate for a low base rate. @ruscio2004checklist describe three admixture-related sampling practices that may lead to pseudotaxonic results. First, when clinical and nonclinical participants are separately recruited and merged into a single sample. Second, when a sample is artificially split into subsamples based on different selection criteria, and these are then used to test different taxometric questions [cf. "subtractive" compound sampling, @haslam2020metaanalysis]. Third, when researchers trim observations from the putative complement (individuals without a diagnosis) to inflate the base rate of the taxon. All these scenarios tend to artificially impose categorical structures onto data that might be strictly dimensional.

## Goals of the Present Review

We aimed to critically review the use of taxometric methods in published studies of NDCs. We focused on the most commonly investigated categories: Autism Spectrum Disorder (ASD), Attention-Deficit/Hyperactivity Disorder (ADHD), Learning Disorders, and the closely related condition of Language Impairment/Disorder (the latter constitutes a minor deviation from the preregistration protocol). We excluded Intellectual Disability, whose etiology is often identifiable and taxonic/syndromic by definition (e.g., Down syndrome), or linked to known medical risk factors.

A crucial goal was to assess the methodological quality and credibility of taxometric findings. We specifically evaluated potential sources of bias, such as artificial admixture, and assessed whether studies provided sufficient methodological information to evaluate other known threats to validity, including low indicator validity, high nuisance covariance, and indicators skewness [extreme skewness can also create the illusion of categorical structures, @ruscio2004boundaryissues; @ruscio2004checklist, and it might be relevant when assessing rare or extreme behaviors].

Finally, we conduct a Monte Carlo simulation study to empirically illustrate the extent to which artificial admixture can lead to the risk to reaching taxonic conclusions in otherwise dimensional data. We simulate a dimensional scenario where clinical and nonclinical participants are separately recruited and merged into a single sample; taxometric (and model-based cluster) analyses are then performed on a set of observed indicators reflecting the latent clinical dimension.

# Methods

The systematic review was conducted in accordance with the *Preferred Reporting items for Systematic Reviews and Meta-Analysis* (PRISMA) 2020 guidelines. A review protocol was preregistered on OSF registries at the following link: https://osf.io/65y9g/?view_only=91e97c6b00dc444abb83fefcf67cbac0

### Sources and Search strategy

A systematic search for relevant peer-reviewed articles was conducted in April 2025 using four electronic databases: PsycINFO, PubMed, Scopus, and Web of Science. No time limits were applied. The following search query, reflecting the methods and populations of interest, was applied to titles, abstracts, keywords:

```         
(("taxometric*" OR "MAMBAC" OR "MAXCOV" OR "MAXEIG" OR "L-Mode") AND 
("autis*" OR "ASD" OR "attention-deficit*" OR "ADHD" OR "learning dis*" 
OR "reading dis*" OR "dyslexia" OR "math* dis*" OR "math* diff*"))
```

In PubMed, where the wildcard `*` was not supported, it was replaced with full terms (e.g., `"disorder"`, `"disability"` instead of `"dis*"`; `"mathematical"`, `"mathematics"`, `"math"` instead of `"math*"`).

Language disorder was subsequently added as a deviation from the preregistered protocol, replacing the second part of the search query with:

```         
("language imp*" OR "language dis*")
```

Additionally, the full search query was launched on Google Scholar, and the first 10 pages of results were screened manually. References cited in, and articles citing, @haslam2020metaanalysis were also screened via Google Scholar. Finally, an exploratory search using OpenAI’s GPT-4o “Deep Research” tool was conducted, providing the preregistration protocol as context. All additional promising records identified through these methods were listed under the *“Identification of studies via other methods”* section of the flowchart.

### Eligibility Criteria

Inclusion criteria were:

1.  The study applied at least one taxometric procedure (MAMBAC, MAXCOV, MAXEIG, L-Mode, MAXSLOPE; other procedures would be considered if explicitly described as taxometric);
2.  The target population consisted of individuals with NDCs/traits;
3.  The study drew a conclusion about the latent structure (categorical vs. dimensional) or reported sufficient information (e.g., CCFIs) to infer a conclusion.

Exclusion criteria were:

1.  The article was theoretical, methodological, simulation study without empirical data;
2.  The study did not analyze behavioral data;
3.  The study was a review and/or meta-analysis.

The search was limited to published, peer-reviewed journal articles, as we aimed to provide a critical review of the existing high-quality literature. Only one potentially relevant non-journal record was identified and, while excluded from the systematic review, is commented separately in the Discussion.

### Screening and Coding

Two independent human coders (MC and RP) screened and coded all articles. All discrepancies were resolved through discussion and were later reviewed by the PI (ET).

Since a single article could report multiple (sub)samples and/or taxometric analyses, the full coded dataset followed a long-form data structure, with articles appearing across multiple rows. Coded variables were defined in the data dictionary included in the preregistration protocol, with a few additional fields added to capture coder notes and agreement metrics.

Inter-coder agreement was fair to good across all phases. In the title and abstract screening phase, Cohen’s *κ*=0.79 (34 out of 38 independent decisions matched). In the full-text eligibility screening, Cohen’s *κ*=0.52 (15 out of 19). For the final data extraction, 84% of rows (71 out of 85) were extracted by both coders. Agreement on critical variables was high: for the “authors’ taxonic conclusion” agreement was 94%; for “artificial admixture”, it was 95% at the (sub)sample level.

# Results

A total of 110 records were identified through database searches. After removing 67 duplicates and excluding 5 additional records (dissertations or book chapters, only one of which appeared to include primary taxometric analyses but could not be retrieved), 38 articles were screened for title/abstract. Nineteen records were excluded at this stage. Full-text assessment was then conducted on the remaining 19 articles, of which 7 were excluded for not meeting the inclusion criteria. An additional 4 records were identified through citation tracking and online browsing, of which 2 were included in the final review. The PRISMA flowchart in @fig-prisma summarizes the study selection process.

@fig-prisma *about here*

![PRISMA 2020 flow diagram illustrating the study screening and selection process](Figures/PRISMA_flow_diagram.png){#fig-prisma}

```{r}
df = data.frame(read_excel("../Literature-review/data/data_extraction.xlsx"))
```

A summary of the included studies, simplified to one row per article, is presented in @tbl-summary. A full reporting of all coded data for each individual taxometric analysis is available in the Supplemental Online Material. The total number of taxometric analyses was `r nrow(df)`, ranging from `r min(table(df$ID_article))` to `r max(table(df$ID_article))` per article. Targeted disorders were ADHD (6 articles), ASD (6 articles), dyslexia (1 article), and Specific Language Impairment (SLI; 2 articles), with one article addressing both ADHD and ASD. Most articles (10 out of 14) examined whether a given disorder constituted a taxon, while the remaining 4 focused on whether putative subtypes within a disorder showed taxonic structure.

The most commonly used taxometric method was MAMBAC, applied in 13 out of 14 articles and in `r sum(grepl("MAMBAC", df$Taxometric_methods_used))` out of `r nrow(df)` total analyses. This was followed by MAXEIG (9 articles), L-Mode (7 articles), MAXCOV (2 articles), and MAXSLOPE (1 article). Most studies employed more than one taxometric procedure, with a median of `r median(str_count(df$Taxometric_methods_used, ";") + 1)` methods per analysis. In 11 out of 14 articles, interpretation was based on a quantitative fit index (Fit~d~ or, in more recent studies, the CCFI), while the remaining 3 relied on visual inspection of taxometric curves. The number of indicators entered into analyses ranged from `r min(df$Indicators_number, na.rm = TRUE)` to `r max(df$Indicators_number, na.rm = TRUE)`, with a median of `r median(df$Indicators_number, na.rm = TRUE)` (excluding one article in which the number was not clearly reported). The median sample size across all analyses was `r median(df$Sample_size)`, or `r median((df |> group_by(ID_article) |> summarize(avg = mean(Sample_size)))$avg)` when averaged within articles.

Taxonic conclusions were mixed. All five articles targeting ADHD as a disorder concluded in favor of a dimensional structure, as did both articles focusing on SLI. In contrast, all four articles examining ASD as a disorder leaned toward, or explicitly supported, a categorical (taxonic) structure. The remaining four articles investigated subtypes of disorders, and all favored taxonic conclusions, either predominantly [@stevens2018functional on ADHD subtypes; @munson2008asd on ASD subtypes; @obrien2012dyslexia on dyslexia subtypes], or partially [@ingram2008defining supported taxonic ASD subtypes depending on the set of indicators used]. In total, 8 out of 14 articles reached a taxonic conclusion in at least some of their taxometric analyses. Specifically, `r sum(df$Taxonic_conclusion)` out of `r nrow(df)` total analyses—representing `r round(mean(df$Taxonic_conclusion) * 100, 1)`%—yielded taxonic results. These were primarily associated with ASD: `r sum(grepl("ASD", df$Target_disorder) & df$Taxonic_conclusion == 1)` out of `r sum(grepl("ASD", df$Target_disorder))` analyses involving ASD (i.e., `r round(100 * sum(grepl("ASD", df$Target_disorder) & df$Taxonic_conclusion == 1) / sum(grepl("ASD", df$Target_disorder)), 1)`%) supported a categorical structure.

Artificial admixture was evident or strongly suspected in at least part of the analyses in 8 out of 14 articles (including all those targeting ASD) and involving a total of `r sum(df$Artificial_admixture)` out of `r nrow(df)` analyses. Articles that incurred artificial admixture tended to align with those that reached taxonic conclusions: 6 of the 8 articles with suspected admixture also reported taxonic findings. This association was even more pronounced at the level of individual analyses. A taxonic conclusion was reached in `r sum(df$Taxonic_conclusion[df$Artificial_admixture == 1])` out of `r sum(df$Artificial_admixture == 1)` analyses (`r round(100 * mean(df$Taxonic_conclusion[df$Artificial_admixture == 1]), 1)`%) where admixture was evident or suspected. In contrast, only `r sum(df$Taxonic_conclusion[df$Artificial_admixture == 0])` out of `r sum(df$Artificial_admixture == 0)` analyses (`r round(100 * mean(df$Taxonic_conclusion[df$Artificial_admixture == 0]), 1)`%) reached a taxonic conclusion when admixture was likely or certainly

Other methodological issues concerned missing information about key descriptive statistics and validity indices. Nuisance covariance could be coded for only 2 out of 14 articles. Where reported, it was small to negligible in @james2016latent , but exceeded 0.40 for many indicators in @frazier2023asd . Both studies reached a taxonic conclusion. Skewness of indicator score distributions was reported in only 5 articles, where skewness values were often near or beyond ±1 for at least one indicator in about one-third of analyses. However, there was no clear association between skewness and whether a taxonic conclusion was reached. By contrast, indicator validity was more consistently reported, and could be coded in all but 3 articles. Where available, it was almost always large or very large (Cohen’s *d* ≫ 1), consistent with best-practice recommendations for taxometric analysis.

@tbl-summary *about here*

```{r}
#| label: tbl-summary
#| tbl-cap: Overview summary of the reviewed articles.
summary_tab = read_excel("Tables/Review-Summary.xlsx",sheet=2)
kable(summary_tab, format = "latex", booktabs = TRUE) |>
  kable_styling(font_size = 8, latex_options = c("striped", "scale_down")) |>
  column_spec(1:ncol(summary_tab),width="5em") |>
  landscape()
```

## Additional Use of Cluster Analysis

Among the 14 identified articles, 6 also employed clustering methods: in 5 cases consisting of latent class/profile analysis (LCA, LPA); the remaining case employing community detection in a graph analysis. In 5 of these 6 articles clustering was conducted in parallel with taxometric analysis [@deserno2023probing; @frazier2007adhd; @frazier2023asd; @james2016latent; @munson2008asd], while in one case it represented a secondary analysis [@frazier2010asd]. All six studies targeted ADHD and/or ASD, and in all cases clustering results were interpreted as supporting taxonic conclusions. These interpretations generally converged with those from taxometric analysis, with one exception: in @frazier2007adhd, clustering results inconclusively suggested the presence of subgroups within ADHD, contrasting with the dimensional structure favored by the taxometric analysis (it is worth reminding that clustering methods do not provide explicit tests of taxonicity). In all but two studies [@frazier2007adhd; @munson2008asd], we identified at least some risk of artificial admixture.

# A Monte Carlo Simulation of Artificial Admixture

Artificial admixture represents a common and powerful threat to validity, but also one that is easily avoidable by design. In our review, it presented a marked risk of bias for studies supporting the taxonic nature of autism. To illustrate the risks associated with artificial admixture, we simulate a dimensional scenario where clinical and nonclinical participants are separately recruited and merged into a single sample

```{r}
load("../R/simulateAdmixtResults.RData")
```

A single normally distributed latent variable $X$ is generated to represent the clinical trait of interest. A set of observed indicators ($x_1$, $x_2$, $x_3$) are then simulated as linear functions of $X$ plus normally distributed random noise, yielding $R^2$ = 0.77 for each indicator. Individuals above the 99^th^ percentile of $X$ are assumed to receive a diagnosis via global clinical assessment. A sample of $N = 1000$ individuals is drawn from the general population. Given the low base rate, only about $n = 10$ cases are expected to naturally receive a diagnosis. To address this, researchers draw a second sample consisting of an additional $n = 1000$, targeting clinically diagnosed cases, and merge it with the original sample. The full simulation code and data are available in the online materials:\
[https://osf.io/ys5ad/?view_only=0e2812acfabf43fc8af01f883c7331ba](#0){.uri}

An instance of the simulation, illustrating two observed variables $x_1$ and $x_2$, is presented in @fig-admixture. Color is used to distinguish individuals with and without a diagnosis, but even without this aid, two clusters visually emerge. This apparent separation is misleading: no latent categories exist in the data. The appearance of a categorical structure is a consequence of artificial admixture. In this simulated example, indicator validity is high (Cohen’s *d* ≈ 2), suggesting strong separation between groups on each variable. However, nuisance covariance is partly problematic: among diagnosed individuals, the correlation between indicators is close to zero ($r \approx 0.05$), whereas among non-diagnosed individuals, it is substantial ($r \approx 0.60$).

@fig-admixture *about here*

![A simulated example of artificial admixture, where a large number of individuals with a diagnosis are separately recruited and added to the sample (total N = 2000). The true underlying structure is strictly dimensional.](Figures/figureAdmixture.png){#fig-admixture}

A Monte Carlo simulation was then conducted with 1000 iterations. Taxometric analyses were performed using the `RTaxometric` package in R. Inference was based on the Comparison Curve Fit Index (CCFI), which ranges from 0 (indicating strong support for a dimensional structure) to 1 (strong support for a categorical structure), with values around 0.5 considered inconclusive. The default procedures (MAMBAC, MAXEIG, and L-Mode) were applied to each simulated dataset. To enable all three procedures, three observed indicators ($x_1$, $x_2$, $x_3$) were included in the simulations.

Over 1000 simulated datasets, results consistently and strongly favored a categorical interpretation: median combined CCFI = `r formatC(median(resultsAdmix$CCFI.mean),2,format="f")`, 95% quantile interval \[`r formatC(quantile(resultsAdmix$CCFI.mean,.025),2,format="f")`, `r formatC(quantile(resultsAdmix$CCFI.mean,.975),2,format="f")`\]; median MAMBAC CCFI = `r formatC(median(resultsAdmix$CCFI.MAMBAC),2,format="f")`; average MAXEIG CCFI= `r formatC(median(resultsAdmix$CCFI.MAXEIG),2,format="f")`; average L-Mode CCFI = `r formatC(median(resultsAdmix$CCFI.LMode),2,format="f")`. The smallest combined CCFI over 1000 iterations was `r formatC(min(resultsAdmix$CCFI.mean),2,format="f")`. Therefore, admixture can be an extremely strong driver of false categorical findings, especially when many clinical cases are separately recruited and added to a sample.

To verify that artificial admixture also produces misleading results when using clustering methods, we ran Gaussian Mixture Models (GMMs) comparing 1-component versus 2-component solutions, using the `mclust` package in R. Model selection was based on the Bayesian Information Criterion (BIC), as per default in GMMs. GMM is a form of model-based clustering grounded in finite mixture modeling. It is conceptually similar to latent profile analysis (LPA; with which it is often confused) but is more flexible in that it models covariances among indicators. Across 1,000 simulated datasets, results consistently favored the 2-component solution over the unimodal alternative. The median difference in BIC (ΔBIC) was `r formatC(median(resultsAdmix$gmmBIC1 - resultsAdmix$gmmBIC2), 2, format = "f")`, in favor of the 2-component model.

To confirm that the categorical structure was incorrectly favored specifically due to artificial admixture, we run a second Monte Carlo simulation using the same dimensional data-generating process as before, but without admixture. In this case, a single sample of $N = 2000$ observations was drawn at each iteration. Therefore, nuisance covariance remains present, but there is no admixture. Median combined CCFI = `r formatC(median(resultsNoAdmix$CCFI.mean),2,format="f")`, 95% quantile interval \[`r formatC(quantile(resultsNoAdmix$CCFI.mean,.025),2,format="f")`, `r formatC(quantile(resultsNoAdmix$CCFI.mean,.975),2,format="f")`\]; median MAMBAC CCFI = `r formatC(median(resultsNoAdmix$CCFI.MAMBAC),2,format="f")`; average MAXEIG CCFI= `r formatC(median(resultsNoAdmix$CCFI.MAXEIG),2,format="f")`; average L-Mode CCFI = `r formatC(median(resultsNoAdmix$CCFI.LMode),2,format="f")`. Clustering with GMM also consistently favored the 1-component model (over the 2-component model), with an average ΔBIC = `r formatC(median(resultsNoAdmix$gmmBIC2-resultsNoAdmix$gmmBIC1),2,format="f")` in favor of the 1-component model.

Thus, without admixture taxometric results leaned towards a dimensional conclusion, but frequently remained inconclusive, probably due to nuisance covariance. It is worth noting, however, that under a dimensional structure achieving both high indicator validity and low within-group covariance might be practically impossible, because indicators that strongly differentiate individuals with and without a diagnosis must be strongly associated with the underlying trait, thus producing inter-indicator covariance.

# Discussion

We found that taxometric analysis remains underused in neurodevelopmental research, which is unfortunate given the unique relevance of this method to the ongoing debate about the nature of NDCs [@astle2022trandiagnostic; @happe2021both; @michelini2024world; @sonuga-barke1998categoricalmodels; @sonuga2020kuhnian]. That underuse was expected, however. @haslam2020metaanalysis classified only 15 out of 183 taxometric studies in the “childhood” category (which included heterogeneous conditions, and even sleep problems). In the studies identified in our review, only ASD, ADHD, and SLI were targeted as disorders in taxometric analysis. None of learning disorders employed taxometric approaches, with Dyslexia being covered in one single article, but only for investigating its subtypes.

Taxometric results appeared relatively consistent. Dimensional conclusions were predominantly reached for ADHD and SLI, while categorical conclusions prevailed for ASD and studies examining subtypes of any disorder. This may seem to offer a compelling answer to the debate raised by @chown2021bit and @happe2021both However, a closer inspection of the methodological limitations in the reviewed studies suggests that such conclusions should be interpreted with caution.

We identified four ASD taxometric analyses, and all of them reached taxonic conclusions, with some degree of artificial admixture. This represents a major threat to validity of the conclusions of these studies, as demonstrated both in our data simulation and in prior literature [@ruscio2004boundaryissues; @ruscio2004checklist]. Admixture in the reviewed studies ranged from sampling participants through different methods, only some of which explicitly targeted clinical populations [@james2016latent], to combining clinical and non-clinical samples [@deserno2023probing; @frazier2023asd]. In one case, inclusion criteria from a larger database were partly unclear, but the sample was explicitly structured by diagnostic status [@deserno2023probing]. Another form of admixture involved constructing a sample of affected and unaffected siblings [@frazier2010asd]. According to our interpretation, the only relatively unbiased taxometric evidence suggesting that ASD may be a taxon as a disorder comes from a secondary analysis by @frazier2010asd, in which only unaffected siblings were examined.

Concerning subtypes, the situation was similar. All four reviewed articles reached some taxonic conclusions, but three of them likely involved some form of artificial admixture. However, the issue appeared to be nuanced and less severe in this subset of studies. For example, @obrien2012dyslexia used psychometric cutoffs across different tools and alternate inclusion criteria, which may not necessarily have biased the results, unless the selection criteria correlate with different underlying cognitive impairments in dyslexia (phonological vs. non-phonological). However, the authors themselves acknowledged this possibility, writing that *“depending on the dyslexia criterion used, samples may vary in composition with regard to their subtypes”* (p.33). A subtle and potentially overlooked cause of admixture in studies targeting subtypes within entirely clinical samples is that the original diagnoses might be based on exceeding cutoff thresholds on partly independent dimensions/scales, reflecting a variant of the second type of problematic sampling listed by @ruscio2004checklist In general, a taxonic structure of subtypes should be regarded as inconsistent, and in principle unlikely, if the main condition as a whole is seen as dimen

Overall, the presence of artificial admixture was most frequently associated with taxonic conclusions. Only two notable mismatches were identified: @marcus2012latent reached a dimensional conclusion regarding ADHD despite having incurred admixture of clinical cases, while @munson2008asd reached a taxonic conclusion about ASD subtypes without evidence of admixture (all children had received an ASD diagnosis based on a seemingly uniform clinical assessment). Together with the above discussed exception in a secondary analysis of a subsample by @frazier2010asd targeting ASD, these findings reinforce the view that ADHD is best conceptualized as dimensional, while ASD may exhibit certain taxonic features. However, the latter conclusion is supported by limited unbiased evidence.

In our simulated example, we showed that artificial admixture represents a major threat to the validity of taxometric analysis, and to clustering methods as well. One might argue that our simulated scenario, in which half of sample was separately recruited, was extreme. However, this design is broadly consistent with the degree of admixture observed in the reviewed literature.

## Conclusions, Limitations, Future Directions

An obvious limitation of the present review concerns the small number of studies identified, and the virtual lack of studies exploring taxa within learning disorders. Furthermore, the available evidence was too scattered and methodologically heterogeneous to conduct a meta-analysis. These limitations are themselves informative, highlighting the need for more taxometric investigation in the field. It is unlikely that many more studies would be included by relaxing eligibility criteria. Exclusion criteria specified the lack of use of behavioral indicators; however, no study was excluded on this basis. One record was screened out for being a dissertation [@clemons2006taxometric]; however, the full document could not be retrieved. Based on its abstract, it focused on whether ADHD subtypes represent distinct taxa, and it reached a taxonic conclusion, but some degree of admixture was possible (as participants were separately recruited from clinical centers and schools).

A relevant future direction concerns a systematic examination of the use and results of cluster analysis, which was employed by some of the reviewed articles, and is a prominent tool in this field [@astle2022trandiagnostic]. Model-based approaches, such as latent class/profile analysis, were the most frequently used. Clustering algorithms are not without problems. First, while they are more flexible and can address broader questions, they do not offer direct or consistent tests of taxonicity [@beauchaine2003taxometrics; @ruscio2004boundaryissues]. Second, meaningful scientific inference from clustering (beyond its use as a mere data reduction technique) requires careful handling of assumptions, as the risk of detecting pseudoclusters is high [@toffalini2022entia; @toffalini2024clusters]. Finally, it is not immune to risks such as artificial admixture. Nonetheless, clustering and taxometric analysis could be more directly, and critically, compared when addressing the question of whether neurodevelopmental conditions reflect categories or dimensions.

A crucial implication of our work concerns how taxometric findings should inform our interpretation of traditional diagnostic categories of NDCs such as those in the DSM-5, which have come under criticism [@astle2022trandiagnostic; @sonuga2020kuhnian; @sonuga2022dontfit]. Although described as atheoretical and agnostic about etiology, the DSM operationalizes disorders in ways that reinforce a neo-Kraepelinian medical paradigm, implicitly reflecting the idea that NDCs reflect discrete categories underpinned by well-defined, specific dysfunctions. This view continues to shape research and clinical practice [@coghill2012categories]. Finding that the latent structure of one or many NDCs is dimensional does not deny the practical utility of diagnostic systems. However, it requires researchers and clinicians to be explicit about their assumptions and models, instead of implicitly reifying categories as natural taxa and overinterpreting their ontological status. High-quality taxometric studies offer a direct solution of the issue. We argue that they deserve a more central role in the study of NDCs.

# References

::: {#refs}
:::
