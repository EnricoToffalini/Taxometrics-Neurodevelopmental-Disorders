---
title: "Tails or Types? A Critical Systematic Review of Taxometric Studies in Neurodevelopmental Disorders"
shorttitle: "Taxometric Review Neurodevelopmental Disorders"
authors:
  - name: Enrico Toffalini
    corresponding: true
    orcid: 0000-0002-1404-5133
    email: enrico.toffalini@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Margherita Calderan
    corresponding: false
    orcid: 0009-0005-5668-5162
    email: margherita.calderan@unipd.it
    affiliation: Department of General Psychology, University of Padua, Italy
  - name: Riccardo Pagan
    corresponding: false
    email: riccardo.pagan.3@studenti.unipd.it
    affiliation: Department of Social and Developmental Psychology, University of Padua, Italy
  - name: Valentina Tobia
    corresponding: false
    email: tobia.valentina@unisr.it
    affiliation: University Vita-Salute San Raffaele, Milan, Italy
author-note:
  disclosures:
    study-registration: 'The review was preregistered at https://osf.io/65y9g/?view_only=91e97c6b00dc444abb83fefcf67cbac0'
    financial-support: 'Financial support: Project 2022KBW99S "Tails or types? Testing the dimensional hypothesis in neurodevelopmental disorders", funded by Next Generation EU, Mission 4, Componente 1, CUP C53D23004210006'
    gratitude: "We are grateful to Athanasia Vasileiadou who first pointed us to some of the reviewed articles."
    data-sharing: null
    related-report: null
    conflict-of-interest: null
    authorship-agreements: null
abstract: "..."
keywords: [Neurodevelopmental disorders, Taxometric analysis, Autism, ADHD, Learning disorders]
bibliography: references.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-typst: default
  apaquarto-pdf:
    documentmode: man
---

In recent years, research on neurodevelopmental disorders (NDDs) has undergone widespread reconsiderations. Traditional diagnostic categories defined in the DSM-5 [@dsm5], have been increasingly called into question in favor of a dimensional and transdiagnostic view [e.g., @astle2022trandiagnostic; @michelini2024world; @happe2020looking; @happe2021both]. The DSM-5 itself has incorporated dimensional aspects, for example in defining a broad Autistic Spectrum Disorder (ASD) condition instead of a set of different autism-related diagnoses. Several arguments have contributed to this: the large heterogeneity within diagnostic groups, the poor alignment between data-driven clusters and DSM-based categories, the frequent comorbidity and phenotypic correlations across conditions, and the idea that individuals with NDDs might represent, at least in part, the tails of developmental continua, that are quantitatively rather than qualitatively different from the so-called neurotypical population [@michelini2024world; @happe2021both; @mammarella2021nocore].

Clarifying whether NDDs truly represent categories, rather than just tails of continuous distributions that span across the population, is important for different reasons. These involve quests about social and personal self-identity by involved individuals, discussions about diagnostic framing, comorbidity, and the choice on interventions in clinical settings, the structuring of classes, schools, and educational methods when dealing with neurodiversity, and applications to research design, planning of studies, and power analysis in research settings [@caviola2024editorial]. But most importantly, this is relevant for our understanding of the ontological status of reality, which should matter for scientific endeavor.

A dimensional approach fits well with long-standing principles in the study of individual differences in psychology, and has long characterized research on intelligence and personality [@caviola2024editorial]. It also seems appropriate for NDDs given accumulating evidence of polygenicity and multifactorial etiology [@plomin2005generalist; @kovas2006generalist; @pennington2012multiple; @astle2020core; @caviola2024editorial; @demontis2023adhdgenome]. In fact, most behavioral traits are believed to be influenced not by one or a few, but by many small, additive causes [@chabris2015fourth]. According to a famous principle known in statistics as the central limit theorem [@fischer2011central], when many individual causes (even discrete ones, e.g., gene variants) add up they converge to a joint distribution that tends to continuity and normality: this is, in fact, the "secret" of the Gaussian distribution. Nonetheless, a principled categorical view still resists in neurodevelopmental research, for example concerning ASD [e.g., @happe2021both; @chown2021bit; @frazier2023asd], subtypes within NDDs [e.g., @burgess2018taxodyslexia] or the possible emergence of new data-driven taxa [@astle2022trandiagnostic].

Adjudicating between whether a clinical diagnostic category is characterized by an underlying structure that is categorical or dimensional is precisely the focus of taxometric analysis, a set of quantitative methods that have been developed since the 1990s [e.g., @meehl1995taxometric]. Since then, taxometric analysis has been widely applied in psychopathology, generally providing evidence that most mental health conditions (e.g., depression, anxiety) are best conceptualized as dimensional rather than categorical [@haslam2012review; @haslam2020metaanalysis]. In brief, taxometric methods such as MAMBAC, MAXCOV, MAXEIG, and L-Mode, leverage patterns of covariation among observed indicators to test alternative competing latent models that are categorical or dimensional [@ruscio2007taxometric; @ruscio2004checklist; @cole2004taxometric]. Such methods have become increasingly refined through simulation-based techniques such as the Comparison Curve Fit Index (CCFI), which provide criteria for objective decision-making [@ruscio2018using].

Despite this, the use of taxometric analysis in neurodevelopmental research has been limited. Most existing studies focus on adult psychopathology, with few exceptions [@beauchaine2003taxometrics; @haslam2020metaanalysis]. @happe2021both and @chown2021bit in their debate on whether ASD is a category or a continuum not even mention the potential of taxometric analysis. In their recent influential article, @astle2022trandiagnostic briefly presents taxometry but gives it little emphasis, prevailing reviewing studies that employ cluster analysis. However, the limitations of clustering for taxometric purposes have been discussed for decades. Clustering algorithms tend to impose (rather than seek) categorical structure, often fail to recover known taxa in simulations, and generally provide weak tests of taxonicity [@beauchaine2003taxometrics]. Recent studies simulating realistic psychological data, characterized by a combination of (even modestly) skewed and correlated indicators, further suggest that common clustering algorithms easily detect pseudoclusters while having low power to test the existence of true taxa [@toffalini2022entia; @toffalini2024clusters]. Indeed, @astle2022trandiagnostic interpret results from clustering studies as evidence that data-driven structures fail to align with the expected DSM-5 categories, rather than as proper tests of taxonicity.

Taxometric analysis is not without limitations, however, some of which are shared with cluster analysis. Commonly cited threats to validity of taxometric conclusions include poor indicator validity, nuisance covariance, low base rate, and artificial admixture \[...\]. Poor indicator validity occurs when taxometric analysis is run on variables that present little mean differences between individuals with and without the target disorder (i.e., putatively, the taxon and the complement). Generally, it is recommended that Cohen's d ≫ 1 on each indicator. Nuisance covariance means that there is strong residual correlations after accounting for taxa (i.e., both within the taxon and the complement), thus reflecting the use of redundant indicators; residual r \> 0.40 is often regarded as problematic. Low base rate means that individuals with the taxonic condition are too few in the sample for taxometric analysis to correctly identify them; n \< 30 is often regarded as problematic. This is obviously a problem when the diagnostic category is rare (e.g., 1-2% of the population). Finally, artificial admixture consists of mixing participants selected or recruited using alternate criteria. This is often (incorrectly) used to compensate for the low base rate, with many individuals with a diagnosis being recruited separately from the rest of the sample to increase the number of observations with the putative taxon. Poor indicator validity and low base rate risk masking detection of taxa, while strong nuisance covariance and artificial admixture risk to detecting pseudotaxa by mimicking categorical structures.

## Goals of the Present Review

The main goal of this systematic review is to critically examine the use of taxometric methods in the study of neurodevelopmental disorders (NDDs) within the published literature. We focused our review on the most commonly studied NDD categories: Autism Spectrum Disorder (ASD), Attention-Deficit/Hyperactivity Disorder (ADHD), and all forms of Specific Learning Disorders (SLDs), along with the closely related condition of Language Disorder/Impairment (the latter was not included in the preregistered protocol and thus constitutes a deviation). We excluded Intellectual Disability, as its etiological basis is often well identified and taxonic by definition in many cases (e.g., Down syndrome), or associated with identifiable medical risk factors. Residual non-syndromic cases, in turn, are thought to reflect the lower tail of general mental ability, and thus as inherently dimensional.

A core aim of the review is to critically assess the methodological quality and credibility of findings reported in published taxometric studies. We evaluated potential sources of bias such as artificial admixture, and whether sufficiently complete methodological information was reported to judge other threats to validity, including low indicator validity, nuisance covariance, and the skewness of indicators. (The latter is relevant when scales assess rare or extreme behaviors, and can create the illusion of categorical structure).

Following this systematic review, we present a Monte Carlo simulation study to empirically demonstrate the extent to which artificial admixture can lead to false detection of categorical latent structures in dimensional data, both when using taxometric analysis and cluster analysis.

# Systematic Review of Taxometric Analysis on NDDs

## Methods

The systematic review was conducted in accordance with the above listed goals, the preregistration protocol, and the PRISMA guidelines. The methods are detailed below.

### Sources and Search strategy

A systematic search was conducted on four databases: PsycINFO, PubMed, Scopus, Web of Science. No time limits were set, however virtually no records from before 1990 were expected, as taxometric methods were not yet developed or diffuse then. The following search query was performed on titles, abstracts, and/or keywords:

((“taxometric\*” OR “MAMBAC” OR “MAXCOV” OR “MAXEIG” OR “L-Mode”) AND (“autis\*” OR “ASD” OR “attention-deficit\*” OR “ADHD” OR “learning dis\*” OR “reading dis\*” OR “dyslexia” OR “math\* dis\*" OR "math\* diff\*"))

Where the wildcard "\*" was not supported (i.e., PubMed) it was replaced with full terms ("disorder", "disability" instead of "dis\*"; "mathematical", "mathematics", "math" instead of "math\*").

Language disorder was subsequently added as a deviation from preregistration, replacing the second part of the above search query with ("language imp\*" OR "language dis\*"). In addition, the full search query was launched on Google Scholar and the first 10 pages were screened; the references of and citations to @haslam2020metaanalysis were searched on Google Scholar for additional results; and a deep research via OpenAI's gpt-4o was launched providing it the preregistration protocol as context. All promising records thus emerging and not previously identified via databases, were listed under the *"Identification of studies via other methods"* section of the PRISMA flowchart.

### Eligibility Criteria

Inclusion criteria:

-   The study applies at least one taxometric procedure (e.g., MAMBAC, MAXCOV, L-Mode, MAXEIG);

-   The target population is individuals with NDDs or related traits;

-   The study draws a conclusion about the latent structure (categorical vs. dimensional) or reports sufficient information for an independent reader to reach a conclusion based on those results (e.g., reports CCFIs).

Exclusion criteria:

-   Theoretical, methodological, or simulation articles without empirical data;

-   Articles not reporting any behavioral data (e.g., only neuroimaging or neurophysiological data);

-   Reviews and/or meta-analyses;

-   Studies using other latent structure methods only (e.g., LPA, mixture modeling) without any taxometric methods being employed.

### Screening and Coding

Two independent human coders (MC and RP) screened and coded all articles. All discrepancies were resolved through discussion, and later revised by the PI (ET). No AI tools were used in the process, except in occasional cases by the human coders to assist them clarify the content of articles.

Since a single article could report multiple (sub)samples and/or multiple taxometric analyses on the same sample, the full coded dataframe followed a long-form data structure, with some articles repeating over multiple rows. Coded variables are listed in the data dictionary table reported in the preregistration protocol, to which a few variables for notes and coders agreement were added.

## Results

# Simulation of Artificial Admixture

We focus on artificial admixture because it is a very powerful threat to validity that could relatively easily be avoided by design when planning a study, and because as suggested by the result of the systematic review presented below, it is unfortunately frequent. There are different types of admixtures; @ruscio2004checklist discusses three cases. First, as mentioned above, the situation where clinical and nonclinical cases are separately recruited and merged. Second, the case of splitting a sample into subsamples (using alternative criteria) and then using those to test different taxometric questions. Third, trimming away observations of the putative complement (i.e., individuals without the disorder) to increase the base rate. All of these procedures artificially impose categorical structures to the data that do not exist in the population. It is worth mentioning that artificial admixture is also a threat for any type of cluster analysis, for the exact same reasons that it is a problem for taxometric analysis.

We simulate a dimensional scenario that makes it visually compelling how artificial admixture of the first type mentioned above creates pseudotaxa. A single normally-distributed latent variable $X$ is generated, that defines the target condition. A series of observed indicators $x1, x2, etc.$ are simulated, incorporating the $X$ latent variable plus some random normally-distributed noise ($R^2 = 0.77$). Individuals above the 99^th^ percentile of $X$ receive a diagnosis via clinical assessment. A sample of $N = 1000$ individuals is collected from the general population. Since the base rate is low (on average, only about $n = 10$ cases are expected to naturally present a diagnosis), researchers select and recruit an additional $n = 1000$ cases with a clinical diagnosis from the general population, thus creating artificial admixture. All data simulation is available in the online materials at xxxxxxxxxxxxxxxx.

An instance of the simulation, plotting two observed variables for illustrative purposes, is shown in @FIGURE_xx. Color is added for further clarity to distinguish individuals with and without a diagnosis, but two clusters still clearly emerge. Indicator validity is good (about $Cohen's$ $d = 2$), while nuisance covariance is partly problematic: for the clinical cases $r \approx 0$, but for the nonclinical cases $r = 0.61$. It is worth reminding that no taxa exist here, and the appearance of a categorical structure is mainly imposed by admixture, as shown below.

A Monte Carlo simulation was then performed, with 1000 iterations. Taxometric analysis was conducted using the "RTaxometric" package of R. As recommended, CCFI was used for inference: CCFI varies between 0 (maximal evidence for dimensional structure) to 1 (maximal evidence for categorical structure), with 0.5 indicating inconclusive results. Performed procedures were, as per default: MAMBAC, MAXEIG, and L-Mode. A third $x3$ observed indicator (similar to those above) was entered to allow conducting all these taxometric procedures. Over 1000 simulated datasets, results always strongly favored a categorical structure: average combined CCFI = xxxx, 95% quantile interval \[xxxx, xxxx\] (average MAMBAC CCFI = xxxx; average MAXEIG CCFI= xxxx; average L-Mode CCFI = xxxx). The smallest combined CCFI over 1000 iterations was xxxx. To confirm that artificial admixture also leads to misleading results when performing clustering, Gaussian Mixture Models (GMM) was also run testing 1 vs 2 components, using the "mclust" package of R: over 1000 iterations, results always favored the 2-component relative to the 1-component model, with an average $\Delta BIC = xxxx$ in favor of the 2-component model.

To confirm that the categorical structure was incorrectly favored specifically because of artificial admixture, we run another Monte Carlo simulation like the one above, but without admixture. In this case, a single sample of $N = 2000$ observations was drawn at each iteration. Therefore, nuisance covariance remains strong, but there is no admixture. Average combined CCFI = xxxx, 95% quantile interval \[xxxx, xxxx\]; average MAMBAC CCFI = xxxx; average MAXEIG CCFI= xxxx; average L-Mode CCFI = xxxx. Largest combined CCFI was xxxx. Thus, results remain frequently around inconclusive, probably due to nuisance covariance, but never strongly favor a categorical structure. GMM also consistently favored the 1-component model (over the 2-component model), with an average $\Delta BIC = xxxx$ in favor of the 1-component model. Therefore, admixture can be an extremely strong driver of false categorical findings, especially when many clinical cases are separately recruited and added to the sample.

# Discussion

The present review suggests that taxometric analysis has been underused in neurodevelopmental research, despite its unique relevance for the recent debate on the categorical vs dimensional nature of disorders [@astle2022trandiagnostic; @michelini2024world; @happe2021both]. Focusing on selected NNDs, we identified 14 relevant records. The underuse of taxometric analysis in this field was expected: @haslam2020metaanalysis identified 183 articles employing taxometric methods on psychopathology, of which only 15 concerned childhood (these included various NNDs but also other conditions such as sleep problems). What is most worrying, many of the articles that we reviewed present serious methodological limitations and/or incomplete reporting of relevant information.

In the simulated example, artificial admixture was also accompanied by large nuisance covariance, although it was demonstrated that the latter posed a less severe problem to inference. In fact, the coexistence of low nuisance covariance and good indicator validity is practically impossible under a dimensional scenario. This is because an indicator can largely separate individuals with vs without a diagnosis if it is strongly related to the latent dimension, but this leads to nuisance covariance across valid indicators. Ultimately, however, such impasse might be interpreted as a direct signal that the true latent structure is dimensional.

While the DSM-5 may appear to promote a categorical model of disorders, it does not explicitly commit to a taxonic view. It is often researchers, not diagnostic manuals, who reify clinical categories as natural kinds, despite their originally pragmatic intent.

The fact that observed scores in psychology often deviate from normality [@micceri1989unicorn] may reflect psychometric characteristics (e.g., skewed indicators when observing times, accuracies, bounded sum scores) rather than the true shape of the underlying latent traits.

# References

::: {#refs}
:::
